# -*- coding: utf-8 -*-
"""seq2seq_siamese.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ge0znrxoOb0ej4jFmX3zAAVZfLMhvq9S
"""

# !wget https://www.dropbox.com/s/kxbmga5p8j8amjt/cvutProfiles_gnumbers.zip?dl=0
# !mv cvutProfiles_gnumbers.zip?dl=0 cvutProfiles_gnumbers.zip
# !unzip cvutProfiles_gnumbers.zip
# !rm cvutProfiles_gnumbers.zip
#
# !pip install unidecode

from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard
from keras.optimizers import SGD
import trainer.gru_hierarchical.model as model
from trainer.modelCheckpoint import ModelCheckpointMLEngine
from typing import List, Optional, Tuple
from keras.utils import multi_gpu_model

import trainer.custom_components as cc
from evaluater.preprocessing import preprocess_values_standard


import numpy as np
import argparse
import json
from sdep.profiler import Profile
import sdep

CHECKPOINT_FILE_PATH = 'best_model.h5'
#
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
# OR
# os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"   # see issue #152
# os.environ["CUDA_VISIBLE_DEVICES"] = ""


def main(data_file, job_dir):
    os.makedirs(job_dir)

    ev = sdep.AuthorityEvaluator(username='andrej', neighbors=20, train_size=0.5, valid_size=0.2)
    train_profiles,  valid_profile = ev.get_train_dataset(data_src="s3")
    joint_model = model.model4()

    joint_model.compile(optimizer="adam", loss=cc.contrastive_loss)

    profile_left_val, profile_right_val, label_val, _ = next(sdep.pairs_generator(valid_profile, 50000))
    left_val = np.array(list(map(lambda x: preprocess_values_standard(x.quantiles, model.MAX_TEXT_SEQUENCE_LEN),
                                 profile_left_val)))
    right_val = np.array(list(map(lambda x: preprocess_values_standard(x.quantiles, model.MAX_TEXT_SEQUENCE_LEN),
                                  profile_right_val)))

    train_data_gen = cc.fit_generator_profile_pairs(train_profiles, model.MAX_TEXT_SEQUENCE_LEN, 200000,
                                                    neg_ratio=2)
    val_loss = 100
    not_improve_count = 0
    for epoch_id in range(model.EPOCHS):
        print(f"Epoch number {epoch_id}  not improve {not_improve_count}")

        [left_train, right_train], label_train = next(train_data_gen)
        history = joint_model.fit(x=[left_train, right_train],
                                  y=label_train,
                                  batch_size=model.BATCH_SIZE,
                                  epochs=1,
                                  validation_data=([left_val, right_val], label_val))

        if val_loss > history.history['val_loss'][0]:
            val_loss = history.history['val_loss'][0]
            print(f"Saving model{epoch_id}")
            joint_model.save(f"{job_dir}/model{epoch_id}_{history.history['val_loss']}.h5")
            not_improve_count = 0
        else:
            not_improve_count += 1


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument('--data-file',
                        required=True,
                        type=str,
                        help='Data file local or GCS', nargs='+')
    parser.add_argument('--job-dir',
                        required=True,
                        type=str,
                        help='GCS or local dir to write checkpoints and export model')
    parse_args, _ = parser.parse_known_args()

    main(**parse_args.__dict__)
