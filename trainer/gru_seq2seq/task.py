# -*- coding: utf-8 -*-
"""seq2seq_siamese.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ge0znrxoOb0ej4jFmX3zAAVZfLMhvq9S
"""

from keras.callbacks import EarlyStopping, TensorBoard

import trainer.gru_seq2seq.model as model
import trainer.custom_components as cc
from trainer.modelCheckpoint import ModelCheckpointMLEngine
from sklearn.model_selection import train_test_split
import argparse
import os

CHECKPOINT_FILE_PATH = 'best_model.h5'


def main(data_file, job_dir):
    input_data, input_decoder_data, target_data = model.load_data(data_file)

    model_seq2seq = model.create_model_onehot()
    os.makedirs(job_dir)
    #
    # train_data, valid_data = train_test_split(list(zip(input_data, input_decoder_data, target_data)), train_size=0.6,
    # #                                           random_state=18)
    # print("Training set has " + str(len(train_data)) + "values!")
    # print("Validation set has " + str(len(valid_data)) + "values!")
    model_seq2seq.compile(optimizer='rmsprop', loss=cc.zero_loss)
    model_seq2seq.summary()
    # valid_data = list(model.convert_to_vec(valid_data, full_unicode=True))
    train_data = list(model.convert_to_vec(list(zip(input_data, input_decoder_data, target_data)), full_unicode=True))
    print("Training set has " + str(len(train_data[0])) + " values!")

    model_seq2seq.fit(x=train_data,
                      y=train_data[2],
                      epochs=model.EPOCHS,
                      batch_size=model.BATCH_SIZE,
                      validation_split=0.3,
                      callbacks=[
                          ModelCheckpointMLEngine(job_dir + '/model.h5', monitor='val_loss', verbose=1,
                                                  save_best_only=True, mode='min'),
                          EarlyStopping(monitor='val_loss', patience=15, verbose=1),
                          TensorBoard(log_dir=job_dir + '/log', write_graph=True, embeddings_freq=0)
                    ])


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--data-file',
                        required=False,
                        type=str,
                        help='Data file local or GCS')
    parser.add_argument('--job-dir',
                        required=False,
                        type=str,
                        help='GCS or local dir to write checkpoints and export model')
    parse_args, _ = parser.parse_known_args()

    main(**parse_args.__dict__)
